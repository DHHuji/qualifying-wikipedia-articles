{"cells":[{"cell_type":"code","execution_count":1,"id":"b498d570-ff8f-4408-a458-8165815a57ab","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b498d570-ff8f-4408-a458-8165815a57ab","executionInfo":{"status":"ok","timestamp":1731919102623,"user_tz":-120,"elapsed":31597,"user":{"displayName":"Nika Faynberg","userId":"05331511943374561365"}},"outputId":"c3a1dfd0-a2b2-4658-88e1-3c73da750616"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wikipedia\n","  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (75.1.0)\n","Collecting pywikibot\n","  Downloading pywikibot-9.5.0-py3-none-any.whl.metadata (17 kB)\n","Collecting mwparserfromhell\n","  Downloading mwparserfromhell-0.6.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n","Collecting pyqt5\n","  Downloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n","Collecting pyqtwebengine\n","  Downloading PyQtWebEngine-5.15.7-cp38-abi3-manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n","Collecting ruamel-yaml\n","  Downloading ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (5.3.0)\n","Collecting datetime\n","  Downloading DateTime-5.5-py3-none-any.whl.metadata (33 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pywikibot) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.8.0)\n","Collecting PyQt5-sip<13,>=12.15 (from pyqt5)\n","  Downloading PyQt5_sip-12.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (421 bytes)\n","Collecting PyQt5-Qt5<5.16.0,>=5.15.2 (from pyqt5)\n","  Downloading PyQt5_Qt5-5.15.15-py3-none-manylinux2014_x86_64.whl.metadata (536 bytes)\n","Collecting PyQtWebEngine-Qt5<5.16.0,>=5.15.0 (from pyqtwebengine)\n","  Downloading PyQtWebEngine_Qt5-5.15.15-py3-none-manylinux2014_x86_64.whl.metadata (568 bytes)\n","Collecting ruamel.yaml.clib>=0.2.7 (from ruamel-yaml)\n","  Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n","Collecting zope.interface (from datetime)\n","  Downloading zope.interface-7.1.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.8.30)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n","Downloading pywikibot-9.5.0-py3-none-any.whl (726 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m726.1/726.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mwparserfromhell-0.6.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (191 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.0/191.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyQt5-5.15.11-cp38-abi3-manylinux_2_17_x86_64.whl (8.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyQtWebEngine-5.15.7-cp38-abi3-manylinux_2_17_x86_64.whl (227 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading DateTime-5.5-py3-none-any.whl (52 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyQt5_Qt5-5.15.15-py3-none-manylinux2014_x86_64.whl (59.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.8/59.8 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyQt5_sip-12.15.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.whl (270 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.5/270.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyQtWebEngine_Qt5-5.15.15-py3-none-manylinux2014_x86_64.whl (90.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (722 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.2/722.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading zope.interface-7.1.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (254 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.2/254.2 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: wikipedia\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=7f8dd0ebe58566c6fe736099e8b9f2a1469b41e8046c1ac16ebab46f52324f98\n","  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n","Successfully built wikipedia\n","Installing collected packages: PyQtWebEngine-Qt5, PyQt5-Qt5, zope.interface, ruamel.yaml.clib, PyQt5-sip, mwparserfromhell, wikipedia, ruamel-yaml, pywikibot, pyqt5, datetime, pyqtwebengine\n","Successfully installed PyQt5-Qt5-5.15.15 PyQt5-sip-12.15.0 PyQtWebEngine-Qt5-5.15.15 datetime-5.5 mwparserfromhell-0.6.6 pyqt5-5.15.11 pyqtwebengine-5.15.7 pywikibot-9.5.0 ruamel-yaml-0.18.6 ruamel.yaml.clib-0.2.12 wikipedia-1.4.0 zope.interface-7.1.1\n"]}],"source":["!pip install wikipedia setuptools pywikibot mwparserfromhell pandas numpy scipy nltk tqdm seaborn pyqt5 pyqtwebengine ruamel-yaml lxml datetime"]},{"cell_type":"code","execution_count":3,"id":"f8d29448-4a36-42bc-987e-bf8bd2b8e8f8","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":894},"id":"f8d29448-4a36-42bc-987e-bf8bd2b8e8f8","executionInfo":{"status":"error","timestamp":1731919128305,"user_tz":-120,"elapsed":303,"user":{"displayName":"Nika Faynberg","userId":"05331511943374561365"}},"outputId":"16755450-b860-4c53-e303-29e43a370290"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"No user-config.py found in directory '/content'.\n\nPlease check that user-config.py is stored in the correct location.\nDirectory where user-config.py is searched is determined as follows:\n\n    Return the directory in which user-specific information is stored.\n\n    This is determined in the following order:\n     1.  If the script was called with a `-dir:` argument, use the\n         directory provided in this argument.\n     2.  If the user has a `PYWIKIBOT_DIR` environment variable, use the\n         value of it.\n     3.  If `user-config` is present in current directory, use the\n         current directory.\n     4.  If `user-config` is present in `pwb.py` directory, use that\n         directory\n     5.  Use (and if necessary create) a `'pywikibot'` folder under\n         `'Application Data'` or `'AppData\\Roaming'` (Windows) or\n         `'.pywikibot'` directory (Unix and similar) under the user's\n         home directory.\n\n    Set `PYWIKIBOT_NO_USER_CONFIG=1` to disable loading user config file\n    (`user-config.py`) or install Pywikibot as a site-package.\n\n    .. versionchanged:: 7.7\n       Added the *config_file* parameter.\n\n    :param test_directory: Assume that a user config file exists in this\n        directory. Used to test whether placing a user config file in this\n        directory will cause it to be selected as the base directory.\n    :param config_file: filename of the user config file\n    ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-168e23a49670>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwikipedia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpywikibot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pywikibot/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpywikibot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpywikibot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpywikibot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__metadata__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__copyright__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__url__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pywikibot/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;31m# Save base_dir for use by other modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_base_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pywikibot/config.py\u001b[0m in \u001b[0;36mget_base_dir\u001b[0;34m(test_directory, config_file)\u001b[0m\n\u001b[1;32m    403\u001b[0m                 \u001b[0;34m'\\n\\n    '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             ) + get_base_dir.__doc__\n\u001b[0;32m--> 405\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m__no_user_config\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'2'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: No user-config.py found in directory '/content'.\n\nPlease check that user-config.py is stored in the correct location.\nDirectory where user-config.py is searched is determined as follows:\n\n    Return the directory in which user-specific information is stored.\n\n    This is determined in the following order:\n     1.  If the script was called with a `-dir:` argument, use the\n         directory provided in this argument.\n     2.  If the user has a `PYWIKIBOT_DIR` environment variable, use the\n         value of it.\n     3.  If `user-config` is present in current directory, use the\n         current directory.\n     4.  If `user-config` is present in `pwb.py` directory, use that\n         directory\n     5.  Use (and if necessary create) a `'pywikibot'` folder under\n         `'Application Data'` or `'AppData\\Roaming'` (Windows) or\n         `'.pywikibot'` directory (Unix and similar) under the user's\n         home directory.\n\n    Set `PYWIKIBOT_NO_USER_CONFIG=1` to disable loading user config file\n    (`user-config.py`) or install Pywikibot as a site-package.\n\n    .. versionchanged:: 7.7\n       Added the *config_file* parameter.\n\n    :param test_directory: Assume that a user config file exists in this\n        directory. Used to test whether placing a user config file in this\n        directory will cause it to be selected as the base directory.\n    :param config_file: filename of the user config file\n    "]}],"source":["import wikipedia\n","import re\n","import pywikibot\n","import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","from tqdm import tqdm\n","tqdm.pandas()\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from urllib.request import urlopen\n","import json\n","from datetime import datetime"]},{"cell_type":"code","execution_count":null,"id":"f68f6d59-0199-4db8-89d7-abf6fd9d01f7","metadata":{"id":"f68f6d59-0199-4db8-89d7-abf6fd9d01f7"},"outputs":[],"source":["wikipedia.set_lang(\"en\")  #Limit to English WP"]},{"cell_type":"markdown","id":"d4022b6d-a167-4250-8516-c1d5c4902314","metadata":{"id":"d4022b6d-a167-4250-8516-c1d5c4902314"},"source":["# Creating a manual corpus by providing a list of Wikipedia article titles"]},{"cell_type":"code","execution_count":4,"id":"c570eec3-dfbc-44f4-ada9-8edfa65c279d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c570eec3-dfbc-44f4-ada9-8edfa65c279d","executionInfo":{"status":"ok","timestamp":1731919163091,"user_tz":-120,"elapsed":1886,"user":{"displayName":"Nika Faynberg","userId":"05331511943374561365"}},"outputId":"06fd80f6-9028-4229-d2bb-47738410e275"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your manually created corpus: ['Python (programming language)', 'Artificial intelligence', 'Quantum computing']\n"]}],"source":["def manual_corpus_creation(article_titles):\n","    manual_corpus = []\n","\n","    for article_title in article_titles:\n","        article_title = article_title.strip()  # Remove extra spaces\n","        try:\n","            wikipedia.summary(article_title, auto_suggest=False)\n","            manual_corpus.append(article_title)\n","        except wikipedia.exceptions.PageError:\n","            print(f\"Article '{article_title}' not found on Wikipedia.\")\n","        except wikipedia.exceptions.DisambiguationError:\n","            print(f\"Article '{article_title}' is ambiguous. Skipping.\")\n","\n","    return manual_corpus\n","\n","# Example usage\n","article_titles = [\"Python (programming language)\", \"Artificial intelligence\", \"Quantum computing\"]\n","manual_corpus = manual_corpus_creation(article_titles)\n","print(f\"Your manually created corpus: {manual_corpus}\")"]},{"cell_type":"markdown","id":"fb104c2b-a16b-4d57-9211-67e9d4871469","metadata":{"id":"fb104c2b-a16b-4d57-9211-67e9d4871469"},"source":["## Creation of a dataframe with informations on the pages"]},{"cell_type":"code","execution_count":5,"id":"8b0b98b9-a35b-43fd-8de2-65947c8bbbdb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"8b0b98b9-a35b-43fd-8de2-65947c8bbbdb","executionInfo":{"status":"error","timestamp":1731919176331,"user_tz":-120,"elapsed":303,"user":{"displayName":"Nika Faynberg","userId":"05331511943374561365"}},"outputId":"2d096cb0-a848-495f-bcb7-ebf446703be4"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'pd' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-2ae55108664c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mcrea_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeyword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msection_search\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \"\"\"\n\u001b[1;32m      3\u001b[0m     \u001b[0mCreate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mDataFrame\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mWikipedia\u001b[0m \u001b[0marticles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msearch\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0msearch_list\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mthe\u001b[0m \u001b[0marticles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}],"source":["def crea_dataframe(search_list: list, keyword: str, section_search=False) -> pd.DataFrame:\n","    \"\"\"\n","    Create a DataFrame from Wikipedia articles in the search list.\n","\n","    :param search_list: List containing the name of all the articles.\n","    :param keyword: String containing the keyword to search within sections.\n","    :param section_search: If True, extract the wikitext of the section containing the keyword in its name.\n","    :type section_search: bool\n","    :returns: DataFrame containing the article name, URL, and wikitext for each article.\n","    :rtype: pd.DataFrame\n","    \"\"\"\n","    tableau = []  # List to hold dictionaries with information for each page\n","\n","    # Regular expressions for section, subsection, and subsubsection\n","    recode = r'(== .*' + re.escape(keyword) + r'.* ==)(.*?)(?== )'\n","    recode2 = r'(=== .*' + re.escape(keyword) + r'.* ===)(.*?)(?=== )'\n","    recode3 = r'(==== .*' + re.escape(keyword) + r'.* ====)(.*?)(?==== )'\n","\n","    # Loop through all the articles in the search list\n","    for i in tqdm(range(len(search_list))):\n","        try:\n","            # Find the Wikipedia page\n","            page = wikipedia.page(search_list[i], auto_suggest=False)\n","            page_title = page.title  # Clean name of the page\n","            page_url = page.url  # URL of the page\n","            page_text = page.content  # Retrieve the full content of the article\n","\n","            if section_search:\n","                # If section search is enabled, use regular expressions to find specific sections\n","                page_text_sections = re.findall(recode, page_text) or re.findall(recode2, page_text) or re.findall(recode3, page_text)\n","                if page_text_sections:\n","                    page_text = '\\n'.join([section[1] for section in page_text_sections])\n","                else:\n","                    page_text = \"Section with the given keyword not found.\"\n","\n","            # Add the info to the list\n","            infopage = {'Name only': page_title, 'page url': page_url, 'text': page_text}\n","            tableau.append(infopage)\n","\n","        except wikipedia.exceptions.PageError:\n","            print(f\"PageError: {search_list[i]} not found.\")\n","        except wikipedia.exceptions.DisambiguationError:\n","            print(f\"DisambiguationError: {search_list[i]} is ambiguous.\")\n","        except Exception as e:\n","            print(f\"Error processing {search_list[i]}: {e}\")\n","\n","    # Create DataFrame from the list of dictionaries\n","    df = pd.DataFrame.from_dict(tableau)\n","    return df\n","\n","# Assuming you have already created manual_corpus using manual_corpus_creation()\n","# You can then call the function like this:\n","keyword = \"Technology\"  # Example keyword to search within sections\n","df = crea_dataframe(manual_corpus, keyword, section_search=False)\n","df"]},{"cell_type":"code","source":["# prompt: please explain the keyword meaning in the chunk of code above. It means that if I put True instead of False I can search by the keyword in the section names? But if it's Falst, then this search isn't conducted, right?\n","\n","Okay, let's break down the `section_search` parameter in your code.\n","\n","**Explanation**\n","\n","- **Purpose:** The `section_search` parameter controls whether your function will look for a specific keyword within section names within the Wikipedia page.\n","\n","- **Behavior:**\n","   - If `section_search` is set to `True`, the function will try to find sections within the Wikipedia page whose names contain the specified `keyword`.\n","   - If such a section is found, its content (`page_text`) will be updated to contain only the extracted content of that specific section.\n","   - If `section_search` is set to `False`, the function will skip this step, and `page_text` will contain the entire content of the Wikipedia article.\n","\n","**Example**\n","- If you set `section_search=True` and your `keyword` is \"History\", the function will try to find a section title like \"History of...\" or \"The history of...\". If it finds it, it will collect the content specifically belonging to that section.\n","- If you set `section_search=False`, the entire content of the Wikipedia page will be captured in the `page_text`.\n","\n","**In essence:**\n","\n","- `section_search=True`: Extract content from sections whose names contain the `keyword`.\n","- `section_search=False`: Extract the entire Wikipedia page content without considering the `keyword` for section filtering.\n","\n","**Your understanding is correct:** Setting `section_search` to `True` will enable the search for the `keyword` within the section names and the extraction of the corresponding sections' content. If it's `False`, this search won't be conducted.\n","\n","I hope this clarifies the role of the `section_search` parameter. Let me know if you have any further questions."],"metadata":{"id":"1_WDxhLacHJ0"},"id":"1_WDxhLacHJ0","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"9095372a-e4a1-441d-8a78-f0b0fcdf6919","metadata":{"id":"9095372a-e4a1-441d-8a78-f0b0fcdf6919"},"source":["## Adding WikiData page links"]},{"cell_type":"code","execution_count":null,"id":"f8291ec7-2b07-493c-87e2-27a99d750516","metadata":{"id":"f8291ec7-2b07-493c-87e2-27a99d750516","outputId":"e7d5061c-6d9a-407b-a06c-1ca5c900cb89"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name only</th>\n","      <th>page url</th>\n","      <th>text</th>\n","      <th>wikidata_url</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Python (programming language)</td>\n","      <td>https://en.wikipedia.org/wiki/Python_(programm...</td>\n","      <td>Python is a high-level, general-purpose progra...</td>\n","      <td>https://www.wikidata.org/wiki/Q28865</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Artificial intelligence</td>\n","      <td>https://en.wikipedia.org/wiki/Artificial_intel...</td>\n","      <td>Artificial intelligence (AI), in its broadest ...</td>\n","      <td>https://www.wikidata.org/wiki/Q11660</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Quantum computing</td>\n","      <td>https://en.wikipedia.org/wiki/Quantum_computing</td>\n","      <td>A quantum computer is a computer that exploits...</td>\n","      <td>https://www.wikidata.org/wiki/Q17995793</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       Name only  \\\n","0  Python (programming language)   \n","1        Artificial intelligence   \n","2              Quantum computing   \n","\n","                                            page url  \\\n","0  https://en.wikipedia.org/wiki/Python_(programm...   \n","1  https://en.wikipedia.org/wiki/Artificial_intel...   \n","2    https://en.wikipedia.org/wiki/Quantum_computing   \n","\n","                                                text  \\\n","0  Python is a high-level, general-purpose progra...   \n","1  Artificial intelligence (AI), in its broadest ...   \n","2  A quantum computer is a computer that exploits...   \n","\n","                              wikidata_url  \n","0     https://www.wikidata.org/wiki/Q28865  \n","1     https://www.wikidata.org/wiki/Q11660  \n","2  https://www.wikidata.org/wiki/Q17995793  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["def get_wikidata_url(wikipedia_url):\n","    # Extract the article title from the URL\n","    title = wikipedia_url.split('/wiki/')[-1]\n","    # Query the Wikidata API\n","    response = requests.get(f'https://www.wikidata.org/w/api.php?action=wbgetentities&sites=enwiki&titles={title}&format=json')\n","    data = response.json()\n","    entities = data.get('entities')\n","    if entities:\n","        entity_id = list(entities.keys())[0]\n","        if entity_id != '-1':\n","            return f'https://www.wikidata.org/wiki/{entity_id}'\n","    return ''\n","\n","df_WD = df.copy()\n","# Apply the function to the DataFrame\n","df_WD['wikidata_url'] = df_WD['page url'].apply(get_wikidata_url)\n","\n","df_WD"]},{"cell_type":"markdown","id":"986d1695-1e09-4d33-812f-dfd651bb1519","metadata":{"id":"986d1695-1e09-4d33-812f-dfd651bb1519"},"source":["## Adding the Creation Dates of Wikipedia and Wikidata pages"]},{"cell_type":"code","execution_count":null,"id":"a1d91960-1e43-4104-a57d-e99fff641bd4","metadata":{"id":"a1d91960-1e43-4104-a57d-e99fff641bd4","outputId":"98bba06b-2292-440b-aa10-c0bd3af7dde8"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name only</th>\n","      <th>page url</th>\n","      <th>text</th>\n","      <th>wikidata_url</th>\n","      <th>Wikipedia Creation Date</th>\n","      <th>Wikidata Creation Date</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Python (programming language)</td>\n","      <td>https://en.wikipedia.org/wiki/Python_(programm...</td>\n","      <td>Python is a high-level, general-purpose progra...</td>\n","      <td>https://www.wikidata.org/wiki/Q28865</td>\n","      <td>2001-10-29 18:24:39</td>\n","      <td>2012-11-12 05:29:01</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Artificial intelligence</td>\n","      <td>https://en.wikipedia.org/wiki/Artificial_intel...</td>\n","      <td>Artificial intelligence (AI), in its broadest ...</td>\n","      <td>https://www.wikidata.org/wiki/Q11660</td>\n","      <td>2001-10-08 16:55:49</td>\n","      <td>2012-11-04 04:03:34</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Quantum computing</td>\n","      <td>https://en.wikipedia.org/wiki/Quantum_computing</td>\n","      <td>A quantum computer is a computer that exploits...</td>\n","      <td>https://www.wikidata.org/wiki/Q17995793</td>\n","      <td>2001-10-21 16:10:53</td>\n","      <td>2014-09-06 23:39:30</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       Name only  \\\n","0  Python (programming language)   \n","1        Artificial intelligence   \n","2              Quantum computing   \n","\n","                                            page url  \\\n","0  https://en.wikipedia.org/wiki/Python_(programm...   \n","1  https://en.wikipedia.org/wiki/Artificial_intel...   \n","2    https://en.wikipedia.org/wiki/Quantum_computing   \n","\n","                                                text  \\\n","0  Python is a high-level, general-purpose progra...   \n","1  Artificial intelligence (AI), in its broadest ...   \n","2  A quantum computer is a computer that exploits...   \n","\n","                              wikidata_url Wikipedia Creation Date  \\\n","0     https://www.wikidata.org/wiki/Q28865     2001-10-29 18:24:39   \n","1     https://www.wikidata.org/wiki/Q11660     2001-10-08 16:55:49   \n","2  https://www.wikidata.org/wiki/Q17995793     2001-10-21 16:10:53   \n","\n","  Wikidata Creation Date  \n","0    2012-11-12 05:29:01  \n","1    2012-11-04 04:03:34  \n","2    2014-09-06 23:39:30  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Function to get Wikipedia article creation date\n","def get_wikipedia_creation_date(page_url):\n","    if pd.isna(page_url):\n","        return None\n","    page_title = page_url.split('/')[-1]\n","    endpoint = f\"https://en.wikipedia.org/w/api.php?action=query&prop=revisions&rvlimit=1&rvdir=newer&titles={page_title}&format=json\"\n","\n","    response = requests.get(endpoint)\n","    data = response.json()\n","    page_id = next(iter(data['query']['pages']))\n","\n","    if 'revisions' in data['query']['pages'][page_id]:\n","        creation_date = data['query']['pages'][page_id]['revisions'][0]['timestamp']\n","        creation_date = datetime.strptime(creation_date, '%Y-%m-%dT%H:%M:%SZ')\n","        return creation_date\n","    else:\n","        return None\n","\n","\n","# Function to get Wikidata item creation date\n","def get_wikidata_creation_date(wikidata_url):\n","    if pd.isna(wikidata_url):\n","        return None\n","    entity_id = wikidata_url.split('/')[-1]\n","    endpoint = f\"https://www.wikidata.org/w/api.php?action=query&prop=revisions&rvlimit=1&rvdir=newer&titles=Item:{entity_id}&format=json\"\n","\n","    response = requests.get(endpoint)\n","    data = response.json()\n","    page_id = next(iter(data['query']['pages']))\n","\n","    if 'revisions' in data['query']['pages'][page_id]:\n","        creation_date = data['query']['pages'][page_id]['revisions'][0]['timestamp']\n","        creation_date = datetime.strptime(creation_date, '%Y-%m-%dT%H:%M:%SZ')\n","        return creation_date\n","    else:\n","        return None\n","\n","df_DOB = df_WD.copy()\n","# Add new columns for creation dates\n","df_DOB['Wikipedia Creation Date'] = df_DOB['page url'].apply(get_wikipedia_creation_date)\n","df_DOB['Wikidata Creation Date'] = df_DOB['wikidata_url'].apply(get_wikidata_creation_date)\n","\n","df_DOB"]},{"cell_type":"markdown","id":"a910e4e3-5d4b-47c8-90db-66ea62dd6c8a","metadata":{"id":"a910e4e3-5d4b-47c8-90db-66ea62dd6c8a"},"source":["## Adding the first level of WD properties"]},{"cell_type":"code","execution_count":null,"id":"db3eb79d-08c4-42fe-af6f-f1cc2d4c3524","metadata":{"id":"db3eb79d-08c4-42fe-af6f-f1cc2d4c3524","outputId":"5eb08620-51ef-4d69-9e1c-b2a295529a7c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name only</th>\n","      <th>page url</th>\n","      <th>text</th>\n","      <th>wikidata_url</th>\n","      <th>instance_of</th>\n","      <th>part_of</th>\n","      <th>subclass_of</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Python (programming language)</td>\n","      <td>https://en.wikipedia.org/wiki/Python_(programm...</td>\n","      <td>Python is a high-level, general-purpose progra...</td>\n","      <td>https://www.wikidata.org/wiki/Q28865</td>\n","      <td>Q899523</td>\n","      <td></td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Artificial intelligence</td>\n","      <td>https://en.wikipedia.org/wiki/Artificial_intel...</td>\n","      <td>Artificial intelligence (AI), in its broadest ...</td>\n","      <td>https://www.wikidata.org/wiki/Q11660</td>\n","      <td>Q268592</td>\n","      <td></td>\n","      <td>Q21198</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Quantum computing</td>\n","      <td>https://en.wikipedia.org/wiki/Quantum_computing</td>\n","      <td>A quantum computer is a computer that exploits...</td>\n","      <td>https://www.wikidata.org/wiki/Q17995793</td>\n","      <td>Q11862829</td>\n","      <td></td>\n","      <td>Q12525525</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       Name only  \\\n","0  Python (programming language)   \n","1        Artificial intelligence   \n","2              Quantum computing   \n","\n","                                            page url  \\\n","0  https://en.wikipedia.org/wiki/Python_(programm...   \n","1  https://en.wikipedia.org/wiki/Artificial_intel...   \n","2    https://en.wikipedia.org/wiki/Quantum_computing   \n","\n","                                                text  \\\n","0  Python is a high-level, general-purpose progra...   \n","1  Artificial intelligence (AI), in its broadest ...   \n","2  A quantum computer is a computer that exploits...   \n","\n","                              wikidata_url instance_of part_of subclass_of  \n","0     https://www.wikidata.org/wiki/Q28865     Q899523                      \n","1     https://www.wikidata.org/wiki/Q11660     Q268592              Q21198  \n","2  https://www.wikidata.org/wiki/Q17995793   Q11862829           Q12525525  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Use the correct column name for Wikidata URLs\n","wikidata_url_column = 'wikidata_url'  # Update this if the column name is different\n","\n","# Function to fetch Wikidata properties\n","def fetch_wikidata_properties(wikidata_url):\n","    if pd.isna(wikidata_url):\n","        return {}, {}, {}\n","\n","    entity_id = wikidata_url.split('/wiki/')[-1]\n","    url = f'https://www.wikidata.org/wiki/Special:EntityData/{entity_id}.json'\n","    response = requests.get(url)\n","    data = response.json()\n","    claims = data['entities'][entity_id]['claims']\n","\n","    instance_of = claims.get('P31', [{}])[0].get('mainsnak', {}).get('datavalue', {}).get('value', {}).get('id', '')\n","    part_of = claims.get('P361', [{}])[0].get('mainsnak', {}).get('datavalue', {}).get('value', {}).get('id', '')\n","    subclass_of = claims.get('P279', [{}])[0].get('mainsnak', {}).get('datavalue', {}).get('value', {}).get('id', '')\n","\n","    return instance_of, part_of, subclass_of\n","\n","df_first_level = df_WD.copy()\n","\n","# Fetch properties for each Wikidata item and add them to the DataFrame\n","df_first_level[['instance_of', 'part_of', 'subclass_of']] = df_first_level[wikidata_url_column].apply(\n","    lambda url: pd.Series(fetch_wikidata_properties(url)))\n","\n","df_first_level"]},{"cell_type":"markdown","id":"65bf8a60-36ed-45b4-b082-cb36957f1095","metadata":{"id":"65bf8a60-36ed-45b4-b082-cb36957f1095"},"source":["#### Retrieving the whole hierarchy of \"subclass of\""]},{"cell_type":"code","execution_count":null,"id":"fb591d30-4ba6-442b-b524-e98483eea3b9","metadata":{"id":"fb591d30-4ba6-442b-b524-e98483eea3b9","outputId":"69b58c13-e891-4273-9ed3-4c38b1aaf1d0"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing: 100%|███████████████████████████████| 3/3 [00:50<00:00, 16.86s/item]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name only</th>\n","      <th>page url</th>\n","      <th>text</th>\n","      <th>wikidata_url</th>\n","      <th>Wikipedia Creation Date</th>\n","      <th>Wikidata Creation Date</th>\n","      <th>subclass_of_hierarchy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Python (programming language)</td>\n","      <td>https://en.wikipedia.org/wiki/Python_(programm...</td>\n","      <td>Python is a high-level, general-purpose progra...</td>\n","      <td>https://www.wikidata.org/wiki/Q28865</td>\n","      <td>2001-10-29 18:24:39</td>\n","      <td>2012-11-12 05:29:01</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Artificial intelligence</td>\n","      <td>https://en.wikipedia.org/wiki/Artificial_intel...</td>\n","      <td>Artificial intelligence (AI), in its broadest ...</td>\n","      <td>https://www.wikidata.org/wiki/Q11660</td>\n","      <td>2001-10-08 16:55:49</td>\n","      <td>2012-11-04 04:03:34</td>\n","      <td>[Q21198, Q120208, Q1156402, Q7048977, Q9420, Q...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Quantum computing</td>\n","      <td>https://en.wikipedia.org/wiki/Quantum_computing</td>\n","      <td>A quantum computer is a computer that exploits...</td>\n","      <td>https://www.wikidata.org/wiki/Q17995793</td>\n","      <td>2001-10-21 16:10:53</td>\n","      <td>2014-09-06 23:39:30</td>\n","      <td>[Q12525525, Q622821, Q104637332, Q3249551, Q45...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       Name only  \\\n","0  Python (programming language)   \n","1        Artificial intelligence   \n","2              Quantum computing   \n","\n","                                            page url  \\\n","0  https://en.wikipedia.org/wiki/Python_(programm...   \n","1  https://en.wikipedia.org/wiki/Artificial_intel...   \n","2    https://en.wikipedia.org/wiki/Quantum_computing   \n","\n","                                                text  \\\n","0  Python is a high-level, general-purpose progra...   \n","1  Artificial intelligence (AI), in its broadest ...   \n","2  A quantum computer is a computer that exploits...   \n","\n","                              wikidata_url Wikipedia Creation Date  \\\n","0     https://www.wikidata.org/wiki/Q28865     2001-10-29 18:24:39   \n","1     https://www.wikidata.org/wiki/Q11660     2001-10-08 16:55:49   \n","2  https://www.wikidata.org/wiki/Q17995793     2001-10-21 16:10:53   \n","\n","  Wikidata Creation Date                              subclass_of_hierarchy  \n","0    2012-11-12 05:29:01                                                 []  \n","1    2012-11-04 04:03:34  [Q21198, Q120208, Q1156402, Q7048977, Q9420, Q...  \n","2    2014-09-06 23:39:30  [Q12525525, Q622821, Q104637332, Q3249551, Q45...  "]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Extract Wikidata IDs from the 'wikidata_url' column\n","df_WD['wikidata_url'] = df_WD['wikidata_url'].astype(str)\n","df_WD['wikidata_id'] = df_WD['wikidata_url'].apply(lambda x: re.search(r'Q\\d+', x).group() if re.search(r'Q\\d+', x) else None)\n","\n","\n","# Function to get the \"subclass of\" hierarchy for a given Wikidata item ID (iterative approach)\n","def get_subclass_of_hierarchy(item_id):\n","    hierarchy = []\n","    stack = [item_id]  # Using a stack for iterative depth-first search\n","    while stack:\n","        current_id = stack.pop()\n","        url = f\"https://www.wikidata.org/w/api.php?action=wbgetentities&ids={current_id}&format=json&props=claims\"\n","        response = requests.get(url).json()\n","        if 'entities' in response and current_id in response['entities']:\n","            claims = response['entities'][current_id].get('claims', {})\n","            if 'P279' in claims:  # P279 is \"subclass of\"\n","                subclass_of_ids = [claim['mainsnak'].get('datavalue', {}).get('value', {}).get('id') for claim in claims['P279'] if claim['mainsnak'].get('datavalue')]\n","                for subclass_of_id in subclass_of_ids:\n","                    if subclass_of_id not in hierarchy:\n","                        hierarchy.append(subclass_of_id)\n","                        stack.append(subclass_of_id)\n","    return hierarchy\n","\n","results = []\n","for i, wikidata_id in enumerate(tqdm(df_WD['wikidata_id'], desc='Processing', unit='item')):\n","    if wikidata_id:\n","        hierarchy = get_subclass_of_hierarchy(wikidata_id)\n","    else:\n","        hierarchy = []\n","    results.append(hierarchy)\n","\n","# Add the results to the DataFrame\n","df_subclass_of = df_DOB.copy()\n","df_subclass_of['subclass_of_hierarchy'] = results\n","\n","df_subclass_of"]},{"cell_type":"markdown","id":"05ff4013-ec1c-48c4-8f60-a791eb159ea6","metadata":{"id":"05ff4013-ec1c-48c4-8f60-a791eb159ea6"},"source":["## Retrieving the whole hierarchy of \"part of\""]},{"cell_type":"code","execution_count":null,"id":"cb80966d-d81a-4177-95c0-5ec52b8adef4","metadata":{"id":"cb80966d-d81a-4177-95c0-5ec52b8adef4","outputId":"3bc2283d-c397-4f08-ba88-11a2ebc31cf5"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing: 100%|███████████████████████████████| 3/3 [00:02<00:00,  1.29item/s]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name only</th>\n","      <th>page url</th>\n","      <th>text</th>\n","      <th>wikidata_url</th>\n","      <th>Wikipedia Creation Date</th>\n","      <th>Wikidata Creation Date</th>\n","      <th>part_of_hierarchy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Python (programming language)</td>\n","      <td>https://en.wikipedia.org/wiki/Python_(programm...</td>\n","      <td>Python is a high-level, general-purpose progra...</td>\n","      <td>https://www.wikidata.org/wiki/Q28865</td>\n","      <td>2001-10-29 18:24:39</td>\n","      <td>2012-11-12 05:29:01</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Artificial intelligence</td>\n","      <td>https://en.wikipedia.org/wiki/Artificial_intel...</td>\n","      <td>Artificial intelligence (AI), in its broadest ...</td>\n","      <td>https://www.wikidata.org/wiki/Q11660</td>\n","      <td>2001-10-08 16:55:49</td>\n","      <td>2012-11-04 04:03:34</td>\n","      <td>[]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Quantum computing</td>\n","      <td>https://en.wikipedia.org/wiki/Quantum_computing</td>\n","      <td>A quantum computer is a computer that exploits...</td>\n","      <td>https://www.wikidata.org/wiki/Q17995793</td>\n","      <td>2001-10-21 16:10:53</td>\n","      <td>2014-09-06 23:39:30</td>\n","      <td>[]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       Name only  \\\n","0  Python (programming language)   \n","1        Artificial intelligence   \n","2              Quantum computing   \n","\n","                                            page url  \\\n","0  https://en.wikipedia.org/wiki/Python_(programm...   \n","1  https://en.wikipedia.org/wiki/Artificial_intel...   \n","2    https://en.wikipedia.org/wiki/Quantum_computing   \n","\n","                                                text  \\\n","0  Python is a high-level, general-purpose progra...   \n","1  Artificial intelligence (AI), in its broadest ...   \n","2  A quantum computer is a computer that exploits...   \n","\n","                              wikidata_url Wikipedia Creation Date  \\\n","0     https://www.wikidata.org/wiki/Q28865     2001-10-29 18:24:39   \n","1     https://www.wikidata.org/wiki/Q11660     2001-10-08 16:55:49   \n","2  https://www.wikidata.org/wiki/Q17995793     2001-10-21 16:10:53   \n","\n","  Wikidata Creation Date part_of_hierarchy  \n","0    2012-11-12 05:29:01                []  \n","1    2012-11-04 04:03:34                []  \n","2    2014-09-06 23:39:30                []  "]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Function to get the \"part of\" hierarchy for a given Wikidata item ID (iterative approach)\n","def get_part_of_hierarchy(item_id):\n","    hierarchy = []\n","    stack = [item_id]  # Using a stack for iterative depth-first search\n","    while stack:\n","        current_id = stack.pop()\n","        url = f\"https://www.wikidata.org/w/api.php?action=wbgetentities&ids={current_id}&format=json&props=claims\"\n","        response = requests.get(url).json()\n","        if 'entities' in response and current_id in response['entities']:\n","            claims = response['entities'][current_id].get('claims', {})\n","            if 'P361' in claims:  # P361 is \"part of\"\n","                part_of_ids = [claim['mainsnak'].get('datavalue', {}).get('value', {}).get('id') for claim in claims['P361'] if claim['mainsnak'].get('datavalue')]\n","                for part_of_id in part_of_ids:\n","                    if part_of_id not in hierarchy:\n","                        hierarchy.append(part_of_id)\n","                        stack.append(part_of_id)\n","    return hierarchy\n","\n","results_part_of = []\n","\n","for i, wikidata_id in enumerate(tqdm(df_WD['wikidata_id'], desc='Processing', unit='item')):\n","    if wikidata_id:\n","        hierarchy = get_part_of_hierarchy(wikidata_id)\n","    else:\n","        hierarchy = []\n","    results_part_of.append(hierarchy)\n","\n","# Add the results to the DataFrame\n","df_part_of = df_DOB.copy()\n","df_part_of['part_of_hierarchy'] = results_part_of\n","\n","df_part_of"]},{"cell_type":"markdown","id":"38e6e7e1-93fc-41ee-9b15-c28165cba066","metadata":{"id":"38e6e7e1-93fc-41ee-9b15-c28165cba066"},"source":["## Retrieving the whole hierarchy of \"instance of\""]},{"cell_type":"code","execution_count":null,"id":"10eb6396-456f-4447-8dae-e7321a12a300","metadata":{"id":"10eb6396-456f-4447-8dae-e7321a12a300","outputId":"8892cdf9-45b3-44a2-8040-573e59488e7f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing: 100%|███████████████████████████████| 3/3 [00:25<00:00,  8.55s/item]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name only</th>\n","      <th>page url</th>\n","      <th>text</th>\n","      <th>wikidata_url</th>\n","      <th>wikidata_id</th>\n","      <th>instance_of_hierarchy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Python (programming language)</td>\n","      <td>https://en.wikipedia.org/wiki/Python_(programm...</td>\n","      <td>Python is a high-level, general-purpose progra...</td>\n","      <td>https://www.wikidata.org/wiki/Q28865</td>\n","      <td>Q28865</td>\n","      <td>[Q899523, Q1268980, Q3839507, Q187432, Q127720...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Artificial intelligence</td>\n","      <td>https://en.wikipedia.org/wiki/Artificial_intel...</td>\n","      <td>Artificial intelligence (AI), in its broadest ...</td>\n","      <td>https://www.wikidata.org/wiki/Q11660</td>\n","      <td>Q11660</td>\n","      <td>[Q268592, Q112057532, Q123370638, Q125161275, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Quantum computing</td>\n","      <td>https://en.wikipedia.org/wiki/Quantum_computing</td>\n","      <td>A quantum computer is a computer that exploits...</td>\n","      <td>https://www.wikidata.org/wiki/Q17995793</td>\n","      <td>Q17995793</td>\n","      <td>[Q11862829, Q110402867, Q19478619, Q151885, Q1...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       Name only  \\\n","0  Python (programming language)   \n","1        Artificial intelligence   \n","2              Quantum computing   \n","\n","                                            page url  \\\n","0  https://en.wikipedia.org/wiki/Python_(programm...   \n","1  https://en.wikipedia.org/wiki/Artificial_intel...   \n","2    https://en.wikipedia.org/wiki/Quantum_computing   \n","\n","                                                text  \\\n","0  Python is a high-level, general-purpose progra...   \n","1  Artificial intelligence (AI), in its broadest ...   \n","2  A quantum computer is a computer that exploits...   \n","\n","                              wikidata_url wikidata_id  \\\n","0     https://www.wikidata.org/wiki/Q28865      Q28865   \n","1     https://www.wikidata.org/wiki/Q11660      Q11660   \n","2  https://www.wikidata.org/wiki/Q17995793   Q17995793   \n","\n","                               instance_of_hierarchy  \n","0  [Q899523, Q1268980, Q3839507, Q187432, Q127720...  \n","1  [Q268592, Q112057532, Q123370638, Q125161275, ...  \n","2  [Q11862829, Q110402867, Q19478619, Q151885, Q1...  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Function to get the \"instance of\" hierarchy for a given Wikidata item ID (iterative approach)\n","def get_instance_of_hierarchy(item_id):\n","    hierarchy = []\n","    stack = [item_id]  # Using a stack for iterative depth-first search\n","    while stack:\n","        current_id = stack.pop()\n","        url = f\"https://www.wikidata.org/w/api.php?action=wbgetentities&ids={current_id}&format=json&props=claims\"\n","        response = requests.get(url).json()\n","        if 'entities' in response and current_id in response['entities']:\n","            claims = response['entities'][current_id].get('claims', {})\n","            if 'P31' in claims:  # P31 is \"instance of\"\n","                instance_of_ids = [claim['mainsnak'].get('datavalue', {}).get('value', {}).get('id') for claim in claims['P31'] if claim['mainsnak'].get('datavalue')]\n","                for instance_of_id in instance_of_ids:\n","                    if instance_of_id not in hierarchy:\n","                        hierarchy.append(instance_of_id)\n","                        stack.append(instance_of_id)\n","    return hierarchy\n","\n","results_instance_of = []\n","\n","for i, wikidata_id in enumerate(tqdm(df_WD['wikidata_id'], desc='Processing', unit='item')):\n","    if wikidata_id:\n","        hierarchy = get_instance_of_hierarchy(wikidata_id)\n","    else:\n","        hierarchy = []\n","    results_instance_of.append(hierarchy)\n","\n","# Add the results to the DataFrame\n","df_instance_of = df_WD.copy()\n","df_instance_of['instance_of_hierarchy'] = results_instance_of\n","df_instance_of"]},{"cell_type":"markdown","id":"fa787648-b6a1-4b96-95aa-dda72d8eea9d","metadata":{"id":"fa787648-b6a1-4b96-95aa-dda72d8eea9d"},"source":["## Retrieving labels of the Wikidata articles"]},{"cell_type":"code","execution_count":null,"id":"5b4cb099-220f-4c1d-92b8-986b3e65e072","metadata":{"id":"5b4cb099-220f-4c1d-92b8-986b3e65e072","outputId":"d2c925d0-dccb-4f25-8cb5-e32130408d83"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name only</th>\n","      <th>page url</th>\n","      <th>text</th>\n","      <th>wikidata_url</th>\n","      <th>instance_of</th>\n","      <th>part_of</th>\n","      <th>subclass_of</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Python (programming language)</td>\n","      <td>https://en.wikipedia.org/wiki/Python_(programm...</td>\n","      <td>Python is a high-level, general-purpose progra...</td>\n","      <td>https://www.wikidata.org/wiki/Q28865</td>\n","      <td>object-based language</td>\n","      <td>None</td>\n","      <td>None</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Artificial intelligence</td>\n","      <td>https://en.wikipedia.org/wiki/Artificial_intel...</td>\n","      <td>Artificial intelligence (AI), in its broadest ...</td>\n","      <td>https://www.wikidata.org/wiki/Q11660</td>\n","      <td>industry</td>\n","      <td>None</td>\n","      <td>computer science</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Quantum computing</td>\n","      <td>https://en.wikipedia.org/wiki/Quantum_computing</td>\n","      <td>A quantum computer is a computer that exploits...</td>\n","      <td>https://www.wikidata.org/wiki/Q17995793</td>\n","      <td>academic discipline</td>\n","      <td>None</td>\n","      <td>computation</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       Name only  \\\n","0  Python (programming language)   \n","1        Artificial intelligence   \n","2              Quantum computing   \n","\n","                                            page url  \\\n","0  https://en.wikipedia.org/wiki/Python_(programm...   \n","1  https://en.wikipedia.org/wiki/Artificial_intel...   \n","2    https://en.wikipedia.org/wiki/Quantum_computing   \n","\n","                                                text  \\\n","0  Python is a high-level, general-purpose progra...   \n","1  Artificial intelligence (AI), in its broadest ...   \n","2  A quantum computer is a computer that exploits...   \n","\n","                              wikidata_url            instance_of part_of  \\\n","0     https://www.wikidata.org/wiki/Q28865  object-based language    None   \n","1     https://www.wikidata.org/wiki/Q11660               industry    None   \n","2  https://www.wikidata.org/wiki/Q17995793    academic discipline    None   \n","\n","        subclass_of  \n","0              None  \n","1  computer science  \n","2       computation  "]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Function to get a label for a Wikidata ID\n","def get_wikidata_label(wikidata_id):\n","    url = f\"https://www.wikidata.org/wiki/Special:EntityData/{wikidata_id}.json\"\n","    response = requests.get(url)\n","    if response.status_code == 200:\n","        data = response.json()\n","        try:\n","            return data['entities'][wikidata_id]['labels']['en']['value']\n","        except KeyError:\n","            return None\n","    else:\n","        return None\n","\n","# Define column names to process\n","columns_to_process = df_first_level[['instance_of', 'part_of', 'subclass_of']] #change to the necessary columns\n","\n","# Extract unique Wikidata IDs from the selected columns\n","unique_wikidata_ids = pd.unique(columns_to_process.values.ravel('K')).tolist()\n","unique_wikidata_ids = [x for x in unique_wikidata_ids if pd.notna(x)]\n","\n","# Get labels for all unique Wikidata IDs\n","wikidata_labels = {wid: get_wikidata_label(wid) for wid in unique_wikidata_ids}\n","\n","# Replace Wikidata IDs with their labels in the selected columns\n","df_labeled = df_first_level.copy()\n","\n","for column in columns_to_process:\n","    df_labeled[column] = df_labeled[column].apply(lambda wid: wikidata_labels.get(wid, wid))\n","\n","df_labeled"]},{"cell_type":"code","execution_count":null,"id":"4d910d08-57c5-4483-9d95-6cf324d41715","metadata":{"id":"4d910d08-57c5-4483-9d95-6cf324d41715","outputId":"8eb23b63-4b85-409a-d9ee-0cd5105da60b"},"outputs":[{"name":"stdout","output_type":"stream","text":["DataFrame saved as Excel file: WikiData_properties_manual_corpus_Technology_2024-10-17_19-17.xlsx\n"]}],"source":["def save_dataframe(df, save_as=\"both\"):\n","# Get the current datetime without seconds\n","    current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n","\n","    # Generate the base file name\n","    file_name_base = f\"WikiData_properties_manual_corpus_{keyword}_{current_time}\"\n","\n","    # Save as Excel\n","    if save_as == \"excel\" or save_as == \"both\":\n","        excel_file_name = file_name_base + \".xlsx\"\n","        df.to_excel(excel_file_name, index=False)\n","        print(f\"DataFrame saved as Excel file: {excel_file_name}\")\n","\n","    # Save as CSV\n","    if save_as == \"csv\" or save_as == \"both\":\n","        csv_file_name = file_name_base + \".csv\"\n","        df.to_csv(csv_file_name, index=False)\n","        print(f\"DataFrame saved as CSV file: {csv_file_name}\")\n","\n","# Example usage:\n","# Choose the name of the dataframe above that you need to save (df, df_part_of, etc.) and place it as the first argument in the parenthesis\n","save_dataframe(df_subclass_of, save_as=\"excel\") # \"csv\", \"excel\" or \"both"]},{"cell_type":"code","execution_count":null,"id":"0ddc99c6-4dcc-4062-b42a-5735e50316ec","metadata":{"id":"0ddc99c6-4dcc-4062-b42a-5735e50316ec"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}